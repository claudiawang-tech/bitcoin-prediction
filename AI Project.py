# -*- coding: utf-8 -*-
"""Untitled29.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/156QXZTIgSgWeOg7Brjgvb996uQEcDLX8
"""

#Import Packages

def TrainAgent(filename):
  #Create Chart Price History Data
  data=pd.read_csv(filename, index_col=[0])
  data.dropna()
  price_history = data[['date', 'open', 'high', 'low', 'close', 'volume']] #chart data
  data.drop(columns=['date', 'open', 'high', 'low', 'close', 'volume'], inplace=True)
  #Create Data Feeds
  coinbase = Exchange("coinbase", service=execute_order)(
      Stream("USD-BTC", price_history['close'].tolist())
  )

  portfolio = Portfolio(USD, [
      Wallet(coinbase, 10000 * USD),
      Wallet(coinbase, 10 * BTC),
  ])

  with Module("coinbase") as coinbase_ns:
      nodes = [Stream(name, data[name].tolist()) for name in data.columns]

  feed = DataFeed([coinbase_ns])
  #Set up the environment
  env = TradingEnvironment(
    feed=feed,
    portfolio=portfolio,
    action_scheme='managed-risk',
    reward_scheme='risk-adjusted',
    window_size=20
  )
  agent = DQNAgent(env)
  agent.train(n_episodes=2, n_steps=round(len(data)*0.8))
  return portfolio, feed, env, agent

def Evaluation(AgentModel):
  #Load the agent
  agent = DQNAgent(env)
  agent.restore(path=AgentModel)
  #Take a random action
  action = agent.env.action_space.sample()
  print(action)
  #Get the state from that action
  state, reward, done, info = agent.env.step(action)
  action = agent.get_action(state)
  print(action)
  #Put it all in a for loop
  n_steps = len(data) - round(len(data) * 0.8)
  step = 0
  while not done and (step < n_steps):
    state, reward, done, info = agent.env.step(action)
    action = agent.get_action(state)
    print('step:', step, '-- action:', action)
    step += 1
  return env

if __name__ == "__main__":
  file="1d_predicts.csv"
  portfolio, feed, env, agent=TrainAgent(file)

#Check feed
feed.next()

#Check next worth
portfolio.performance.net_worth.plot(figsize=(16,10))

portfolio.performance.net_worth.iloc[-1]

AgentModel="agentspolicy_network__6a13834c-d1bf-4718-a4d2-30bff6e3fcc3__001.hdf5"
env=Evaluation(AgentModel)

#Check net worth
env.portfolio.performance.net_worth.plot(figsize=(16,10))

portfolio.performance.net_worth.iloc[-1]